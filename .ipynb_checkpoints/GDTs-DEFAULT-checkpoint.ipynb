{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c3b444-064b-4639-983d-238b3da68ad9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da6025-9b87-41c2-83e2-c1d0d3f9187a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T18:40:25.752167Z",
     "iopub.status.busy": "2022-09-27T18:40:25.751898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorflow==2.9.1 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (2.9.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (3.7.4.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (1.21.5)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (0.24.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (1.15.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (1.34.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (1.12)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (2.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (2.9.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (3.17.3)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (2.9.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (14.0.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (1.6.3)\n",
      "Requirement already satisfied: packaging in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (21.3)\n",
      "Requirement already satisfied: setuptools in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow==2.9.1) (52.0.0.post20210125)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.37.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.6.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.26.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from packaging->tensorflow==2.9.1) (2.4.7)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorflow_addons in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (0.16.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from tensorflow_addons) (2.13.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: keras in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (2.9.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: sklearn in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: livelossplot in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (0.5.4)\n",
      "Requirement already satisfied: ipython in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from livelossplot) (7.27.0)\n",
      "Requirement already satisfied: bokeh in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from livelossplot) (2.3.3)\n",
      "Requirement already satisfied: matplotlib in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from livelossplot) (3.4.3)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from bokeh->livelossplot) (3.0.3)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from bokeh->livelossplot) (8.3.2)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from bokeh->livelossplot) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from bokeh->livelossplot) (3.7.4.3)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from bokeh->livelossplot) (5.4.1)\n",
      "Requirement already satisfied: tornado>=5.1 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from bokeh->livelossplot) (6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from bokeh->livelossplot) (2.8.2)\n",
      "Requirement already satisfied: packaging>=16.8 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from bokeh->livelossplot) (21.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from packaging>=16.8->bokeh->livelossplot) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from python-dateutil>=2.1->bokeh->livelossplot) (1.15.0)\n",
      "Requirement already satisfied: pickleshare in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from ipython->livelossplot) (0.7.5)\n",
      "Requirement already satisfied: pygments in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from ipython->livelossplot) (2.10.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from ipython->livelossplot) (5.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from ipython->livelossplot) (3.0.20)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from ipython->livelossplot) (4.8.0)\n",
      "Requirement already satisfied: backcall in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from ipython->livelossplot) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from ipython->livelossplot) (0.1.3)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from ipython->livelossplot) (52.0.0.post20210125)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from ipython->livelossplot) (0.18.0)\n",
      "Requirement already satisfied: decorator in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from ipython->livelossplot) (5.1.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from jedi>=0.16->ipython->livelossplot) (0.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from pexpect>4.3->ipython->livelossplot) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->livelossplot) (0.2.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from matplotlib->livelossplot) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from matplotlib->livelossplot) (0.10.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tqdm in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (4.63.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pandas in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (1.3.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: joblib in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (1.1.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: dill in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (0.3.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: seaborn in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from seaborn) (1.7.1)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from seaborn) (1.3.3)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from seaborn) (3.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: six in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: scipy in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /home/smarton/anaconda3/envs/XAI/lib/python3.8/site-packages (from scipy) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.9.1\n",
    "!pip install tensorflow_addons\n",
    "!pip install keras\n",
    "!pip install sklearn\n",
    "!pip install livelossplot\n",
    "!pip install tqdm\n",
    "!pip install pandas\n",
    "!pip install joblib\n",
    "!pip install dill\n",
    "!pip install pickle\n",
    "!pip install seaborn\n",
    "!pip install scipy\n",
    "!pip install genetic-tree\n",
    "!pip install numba\n",
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6531aaa-2c26-40f5-8078-d754aceda153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'gdt': {\n",
    "        'depth': 5,\n",
    "        \n",
    "        'learning_rate_index': 0.05,\n",
    "        'learning_rate_values': 0.01,\n",
    "        'learning_rate_leaf': 0.005,\n",
    "                \n",
    "        'initializer_values': 'GlorotUniform', #GlorotUniform\n",
    "        'initializer_index': 'GlorotUniform', #GlorotUniform\n",
    "        'initializer_leaf': 'GlorotUniform', #GlorotUniform\n",
    "        \n",
    "        'optimizer': 'adam', #adam, adamw, amsgrad, Nadam\n",
    "\n",
    "        'batch_size': 512,\n",
    "        'epochs': 10_000,\n",
    "        \n",
    "        'restarts': 10,\n",
    "        'restart_type': 'loss', #'loss', 'metric'\n",
    "        \n",
    "        'early_stopping_epochs': 200,\n",
    "        'early_stopping_type': 'loss', #'loss', 'metric'\n",
    "        'early_stopping_epsilon': 0.0,\n",
    "    },\n",
    "    \n",
    "    'preprocessing': {\n",
    "        'balance_threshold': 0,#.25, #if minclass fraction less than threshold/num_classes | #0=no rebalance, 1=rebalance all\n",
    "        'normalization_technique': 'mean', #'min-max'\n",
    "    },\n",
    "    \n",
    "\n",
    "    'computation': {\n",
    "        'random_seed': 42,\n",
    "        'trials': 10, # fixed to 1 for HPO\n",
    "        \n",
    "        'use_best_hpo_result': False,\n",
    "        'force_depth': False,\n",
    "        \n",
    "        'use_gpu': True,\n",
    "        'gpu_numbers': '4',#'1',\n",
    "        'n_jobs': 20,\n",
    "        'verbosity': 0,\n",
    "        \n",
    "        'hpo': None,#'binary', #'binary', 'multi', 'regression'\n",
    "        'search_iterations': 300,\n",
    "        'cv_num': 3,     \n",
    "        \n",
    "        'metrics_class': ['f1', 'roc_auc', 'accuracy'],\n",
    "        'metrics_reg': ['r2', 'neg_mean_absolute_percentage_error', 'neg_mean_absolute_error', 'neg_mean_squared_error'],\n",
    "        \n",
    "        'eval_metric_class': ['f1', 'roc_auc'], #f1 accuracy\n",
    "        'eval_metric_reg': 'r2', #r2 mae        \n",
    "        \n",
    "        \n",
    "    },\n",
    "    \n",
    "    'benchmarks': {\n",
    "        'sklearn': True,\n",
    "        'GeneticTree': True,\n",
    "        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab8be2-1b4c-4370-a837-9176d15bea41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, ParameterSampler, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "from pydl85 import DL85Classifier\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "if config['computation']['use_gpu']:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(config['computation']['gpu_numbers'])\n",
    "    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "    os.environ['XLA_FLAGS'] = \"--xla_gpu_cuda_data_dir=/usr/local/cuda-11.6\"\n",
    "    os.environ['TF_XLA_FLAGS'] = \"--tf_xla_enable_xla_devices --tf_xla_auto_jit=2\"    \n",
    "else:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'false' \n",
    "#os.environ['TF_XLA_FLAGS'] = \"--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit\" \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "from utilities.utilities_GDT import *\n",
    "from utilities.GDT import *\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from itertools import product\n",
    "from collections.abc import Iterable\n",
    "\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import dill\n",
    "\n",
    "tf.random.set_seed(config['computation']['random_seed'])\n",
    "np.random.seed(config['computation']['random_seed'])\n",
    "random.seed(config['computation']['random_seed'])\n",
    "\n",
    "from datetime import datetime\n",
    "timestr = datetime.utcnow().strftime('%Y-%m-%d--%H-%M-%S%f')\n",
    "print(timestr)\n",
    "os.makedirs(os.path.dirname(\"./evaluation_results/latex_tables/\" + timestr +\"/\"), exist_ok=True)\n",
    "\n",
    "filepath = './evaluation_results/depth' + str(config['gdt']['depth']) + '/' + timestr + '/'\n",
    "Path(filepath).mkdir(parents=True, exist_ok=True)    \n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc5b5a-5142-441a-89c0-5eb42f6e0be3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num XLA-GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2397843-32d2-4579-b197-0686f4a99b54",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e7da9-12bb-467f-919f-4fd510ce6463",
   "metadata": {},
   "source": [
    "## make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e8476-bed1-4005-befb-ddfe0b173b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:# and config['gdt']['objective'] == 'classification':\n",
    "    \n",
    "    dataset_dict, config_training, metrics = prepare_training(identifier = 'BIN:German', config = config)\n",
    "    \n",
    "    model_dict = {}\n",
    "    \n",
    "    verbosity = 1\n",
    "    \n",
    "    model_dict['GDT'] = GDT(number_of_variables = dataset_dict['number_of_variables'],\n",
    "                number_of_classes = dataset_dict['number_of_classes'],\n",
    "                \n",
    "                objective = config_training['gdt']['objective'],\n",
    "                ##normalize = config_training['gdt']['normalize'],\n",
    "                \n",
    "                depth = config_training['gdt']['depth'],\n",
    "                \n",
    "                learning_rate_index = config_training['gdt']['learning_rate_index'],\n",
    "                learning_rate_values = config_training['gdt']['learning_rate_values'],\n",
    "                learning_rate_leaf = config_training['gdt']['learning_rate_leaf'],\n",
    "\n",
    "                optimizer = config_training['gdt']['optimizer'],\n",
    "\n",
    "                dropout = config_training['gdt']['dropout'],\n",
    "\n",
    "                split_index_activation_beta = config_training['gdt']['split_index_activation_beta'],\n",
    "\n",
    "                split_index_activation = config_training['gdt']['split_index_activation'],\n",
    "\n",
    "                output_activation = config_training['gdt']['output_activation'],\n",
    "\n",
    "                activation = config_training['gdt']['activation'],\n",
    "                squeeze_factor = config_training['gdt']['squeeze_factor'],\n",
    "\n",
    "                loss = config_training['gdt']['loss'],\n",
    "\n",
    "                initializer_values = config_training['gdt']['initializer_values'],\n",
    "                initializer_index = config_training['gdt']['initializer_index'],\n",
    "                initializer_leaf = config_training['gdt']['initializer_leaf'],        \n",
    "\n",
    "\n",
    "                random_seed = config_training['computation']['random_seed'],\n",
    "                verbosity = verbosity)#5      \n",
    "        \n",
    "        \n",
    "    history = model_dict['GDT'].fit(dataset_dict['X_train'],\n",
    "              dataset_dict['y_train'],\n",
    "\n",
    "              batch_size=config_training['gdt']['batch_size'], \n",
    "              epochs=config_training['gdt']['epochs'], \n",
    "\n",
    "              restarts = 0,#config_test['gdt']['restarts'], \n",
    "              #restart_type=config_test['gdt']['restart_type'], \n",
    "\n",
    "              #early_stopping_epochs=config_training['gdt']['early_stopping_epochs'], \n",
    "              #early_stopping_type=config_test['gdt']['early_stopping_type'],\n",
    "              #early_stopping_epsilon=config_test['gdt']['early_stopping_epsilon'], \n",
    "\n",
    "              valid_data=(dataset_dict['X_valid'], dataset_dict['y_valid']))\n",
    "    \n",
    "        \n",
    "    model_dict['sklearn'] = DecisionTreeClassifier(max_depth=config_training['gdt']['depth'], \n",
    "                                          random_state=config_training['computation']['random_seed'])\n",
    "    \n",
    "    model_dict['sklearn'].fit(dataset_dict['X_train'], \n",
    "                              dataset_dict['y_train'])\n",
    "    \n",
    "        \n",
    "    model_dict['GeneticTree'] = GeneticTree()\n",
    "    model_dict['GeneticTree'] = model_dict['GeneticTree'].fit(dataset_dict['X_train'].values, \n",
    "                                                              dataset_dict['y_train'].values)        \n",
    "    \n",
    "    \n",
    "    scores_dict = calculate_scores(model_dict = model_dict, \n",
    "                                   dataset_dict = dataset_dict, \n",
    "                                   scores_dict = prepare_score_dict(config=config_training), \n",
    "                                   metrics = metrics)           \n",
    "        \n",
    "    #model.set_params(**config_training['gdt'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0ea348-1da9-4b06-ba8f-ecb83f4bb3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:#if False and config['gdt']['objective'] == 'classification':\n",
    "    normalizer_list = dataset_dict['normalizer_list']\n",
    "    if normalizer_list is not None: \n",
    "        transpose_normalized = []\n",
    "        for i, column_name in enumerate(dataset_dict['X_train']):\n",
    "            column = deepcopy(dataset_dict['X_train'][column_name])\n",
    "            column_new = column\n",
    "            if len(column_new[column_new != 0]) != 0:\n",
    "                column_new[column_new != 0] = normalizer_list[i].inverse_transform([column[column != 0]])\n",
    "                #column_new = normalizer_list[i].inverse_transform(column.reshape(-1, 1)).ravel()\n",
    "            transpose_normalized.append(column_new)\n",
    "        data = pd.DataFrame(np.array(transpose_normalized).transpose(), columns=dataset_dict['X_train'].columns).round(1)\n",
    "        display(data.head())        \n",
    "    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = model_dict['GDT'].plot(normalizer_list=dataset_dict['normalizer_list'])\n",
    "    display(image)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(model_dict['sklearn'], fontsize=10) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8fdfd-7915-4cf6-9d4b-4cde0548cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d847daa6-e20c-4baf-aed5-9b2f63e61698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:# and config['gdt']['objective'] == 'classification':\n",
    "    \n",
    "    dataset_dict, config_training, metrics = prepare_training(identifier = 'BIN:German', config = config)\n",
    "    \n",
    "    model_dict = {}\n",
    "    \n",
    "    verbosity = 1\n",
    "    \n",
    "    model_dict['GDT'] = GDT(number_of_variables = dataset_dict['number_of_variables'],\n",
    "                number_of_classes = dataset_dict['number_of_classes'],\n",
    "                \n",
    "                objective = config_training['gdt']['objective'],\n",
    "                ##normalize = config_training['gdt']['normalize'],\n",
    "                \n",
    "                depth = config_training['gdt']['depth'],\n",
    "                \n",
    "                learning_rate_index = config_training['gdt']['learning_rate_index'],\n",
    "                learning_rate_values = config_training['gdt']['learning_rate_values'],\n",
    "                learning_rate_leaf = config_training['gdt']['learning_rate_leaf'],\n",
    "\n",
    "                optimizer = config_training['gdt']['optimizer'],\n",
    "\n",
    "                dropout = config_training['gdt']['dropout'],\n",
    "\n",
    "                split_index_activation_beta = config_training['gdt']['split_index_activation_beta'],\n",
    "\n",
    "                split_index_activation = config_training['gdt']['split_index_activation'],\n",
    "\n",
    "                output_activation = config_training['gdt']['output_activation'],\n",
    "\n",
    "                activation = config_training['gdt']['activation'],\n",
    "                squeeze_factor = config_training['gdt']['squeeze_factor'],\n",
    "\n",
    "                loss = config_training['gdt']['loss'],\n",
    "\n",
    "                initializer_values = config_training['gdt']['initializer_values'],\n",
    "                initializer_index = config_training['gdt']['initializer_index'],\n",
    "                initializer_leaf = config_training['gdt']['initializer_leaf'],        \n",
    "\n",
    "\n",
    "                random_seed = config_training['computation']['random_seed'],\n",
    "                verbosity = verbosity)#5      \n",
    "        \n",
    "        \n",
    "    history = model_dict['GDT'].fit(dataset_dict['X_train'],\n",
    "              dataset_dict['y_train'],\n",
    "\n",
    "              batch_size=config_training['gdt']['batch_size'], \n",
    "              epochs=config_training['gdt']['epochs'], \n",
    "\n",
    "              restarts = 0,#config_test['gdt']['restarts'], \n",
    "              #restart_type=config_test['gdt']['restart_type'], \n",
    "\n",
    "              #early_stopping_epochs=config_training['gdt']['early_stopping_epochs'], \n",
    "              #early_stopping_type=config_test['gdt']['early_stopping_type'],\n",
    "              #early_stopping_epsilon=config_test['gdt']['early_stopping_epsilon'], \n",
    "\n",
    "              valid_data=(dataset_dict['X_valid'], dataset_dict['y_valid']))\n",
    "    \n",
    "        \n",
    "    model_dict['sklearn'] = DecisionTreeClassifier(max_depth=config_training['gdt']['depth'], \n",
    "                                          random_state=config_training['computation']['random_seed'])\n",
    "    \n",
    "    model_dict['sklearn'].fit(dataset_dict['X_train'], \n",
    "                              dataset_dict['y_train'])\n",
    "    \n",
    "        \n",
    "    model_dict['GeneticTree'] = GeneticTree()\n",
    "    model_dict['GeneticTree'] = model_dict['GeneticTree'].fit(dataset_dict['X_train'].values, \n",
    "                                                              dataset_dict['y_train'].values)        \n",
    "    \n",
    "    \n",
    "    scores_dict = calculate_scores(model_dict = model_dict, \n",
    "                                   dataset_dict = dataset_dict, \n",
    "                                   scores_dict = prepare_score_dict(config=config_training), \n",
    "                                   metrics = metrics)           \n",
    "        \n",
    "    #model.set_params(**config_training['gdt'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7baff9c-93e4-4a5e-974d-9cd705be741f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:#if False and config['gdt']['objective'] == 'classification':\n",
    "    normalizer_list = dataset_dict['normalizer_list']\n",
    "    if normalizer_list is not None: \n",
    "        transpose_normalized = []\n",
    "        for i, column_name in enumerate(dataset_dict['X_train']):\n",
    "            column = deepcopy(dataset_dict['X_train'][column_name])\n",
    "            column_new = column\n",
    "            if len(column_new[column_new != 0]) != 0:\n",
    "                column_new[column_new != 0] = normalizer_list[i].inverse_transform([column[column != 0]])\n",
    "                #column_new = normalizer_list[i].inverse_transform(column.reshape(-1, 1)).ravel()\n",
    "            transpose_normalized.append(column_new)\n",
    "        data = pd.DataFrame(np.array(transpose_normalized).transpose(), columns=dataset_dict['X_train'].columns).round(1)\n",
    "        display(data.head())        \n",
    "    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    image = model_dict['GDT'].plot(normalizer_list=dataset_dict['normalizer_list'])\n",
    "    display(image)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_tree(model_dict['sklearn'], fontsize=10) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f856c6c9-368b-4b75-b0d8-6e7a28e4267c",
   "metadata": {},
   "source": [
    "## Real-World Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba5a88-f82f-465f-9b7a-1e38b60dab60",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70506b46-1c82-4ec7-8d03-2306cb98553f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_list_classification_binary = [\n",
    "                        'BIN:Blood Transfusion',# 748 4\n",
    "                        'BIN:Banknote Authentication',# 1372 4\n",
    "                        'BIN:Titanic',# 891 7 \n",
    "                        'BIN:Raisins',#900 7\n",
    "                        'BIN:Rice',#3810 7\n",
    "                        'BIN:Echocardiogram',#132 8 ###TD\n",
    "                        'BIN:Wisconsin Diagnostic Breast Cancer',# 569 10\n",
    "                        'BIN:Loan House',# 614 11\n",
    "                        'BIN:Heart Failure',# 299 12\n",
    "                        'BIN:Heart Disease',# 303 13\n",
    "                        'BIN:Adult',# 32561 14\n",
    "                        'BIN:Bank Marketing',# 45211 14\n",
    "                        'BIN:Cervical Cancer',# 858 15\n",
    "                        'BIN:Congressional Voting',# 435, 16 ###TD\n",
    "                        'BIN:Absenteeism',# 740 18\n",
    "                        'BIN:Hepatitis',#155 19 ###TD\n",
    "                        'BIN:German',# 1000 20\n",
    "                        'BIN:Mushroom',#8124 22\n",
    "                        'BIN:Credit Card',# 30000 23\n",
    "                        'BIN:Horse Colic',#368 27\n",
    "                        'BIN:Thyroid',#9172 29 ###TD\n",
    "                        'BIN:Spambase',# 4601 57\n",
    "                  ]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5dbeb3-2dee-458d-a721-08ffd364039f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "benchmark_dict = get_benchmark_dict(config=config, eval_identifier='classification') \n",
    "\n",
    "parallel_eval_real_world = Parallel(n_jobs=min(config['computation']['n_jobs'], config['computation']['trials']), verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "evaluation_results_real_world_classification_binary = parallel_eval_real_world(delayed(evaluate_real_world_parallel_nested)(identifier_list=identifier_list_classification_binary[::-1], \n",
    "                                                                                                                           random_seed_data=config['computation']['random_seed']+i,\n",
    "                                                                                                                           random_seed_model=config['computation']['random_seed'],\n",
    "                                                                                                                           config = config,\n",
    "                                                                                                                           benchmark_dict = benchmark_dict,\n",
    "                                                                                                                           metrics = config['computation']['metrics_class'],\n",
    "                                                                                                                           verbosity = -1) for i in range(config['computation']['trials']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af666da4-12b6-4ac2-80c7-b1804d2ddf4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_table_save_results(benchmark_dict=benchmark_dict,\n",
    "                        evaluation_results_real_world=evaluation_results_real_world_classification_binary,\n",
    "                        identifier_list=identifier_list_classification_binary,                            \n",
    "                        identifier_string='binary_test',\n",
    "                        filepath=filepath,\n",
    "                        config=config)      \n",
    "\n",
    "plot_table_save_results(benchmark_dict=benchmark_dict,\n",
    "                        evaluation_results_real_world=evaluation_results_real_world_classification_binary,\n",
    "                        identifier_list=identifier_list_classification_binary,                            \n",
    "                        identifier_string='binary_valid',\n",
    "                        filepath=filepath,\n",
    "                        config=config)  \n",
    "\n",
    "plot_table_save_results(benchmark_dict=benchmark_dict,\n",
    "                        evaluation_results_real_world=evaluation_results_real_world_classification_binary,\n",
    "                        identifier_list=identifier_list_classification_binary,                            \n",
    "                        identifier_string='binary_train',\n",
    "                        filepath=filepath,\n",
    "                        config=config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf42fd-d79c-4049-81b6-129f73287f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:#if False and config['gdt']['objective'] == 'classification':\n",
    "    plot_dt_comparison(evaluation_results_real_world=evaluation_results_real_world_classification_binary,\n",
    "                      identifier_list=identifier_list_classification_binary,\n",
    "                      identifier_string='binary_test',\n",
    "                      timestr=timestr,\n",
    "                      config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc9827-8232-4b11-a71b-fb6763b5d3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identifier_list_classification_multi = [\n",
    "                        'MULT:Iris',# 150 4 3\n",
    "                        'MULT:Balance Scale',# 625 4 3\n",
    "                        'MULT:Car',# 1728 6 4\n",
    "                        'MULT:Glass',# 214 9 6 \n",
    "                        'MULT:Contraceptive',# 1473 9 3 \n",
    "                        'MULT:Solar Flare',# 1389 10 8\n",
    "                        'MULT:Wine',# 178 12 3\n",
    "                        'MULT:Zoo',#101 16 7   ###TD\n",
    "                        'MULT:Lymphography',# 148 18 4 ###TD\n",
    "                        'MULT:Segment',# 2310 19 7\n",
    "                        'MULT:Dermatology',# 366 34 6\n",
    "                        'MULT:Landsat',# 6435 36 6\n",
    "                        'MULT:Annealing',# 798 38 5\n",
    "                        'MULT:Splice',# 3190 60 3\n",
    "                  ]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f7ac5c-50e0-4162-b9b9-4d18fb13d3ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "benchmark_dict = get_benchmark_dict(config=config, eval_identifier='classification')\n",
    "\n",
    "metrics = ['f1', 'roc_auc', 'accuracy']\n",
    "\n",
    "parallel_eval_real_world = Parallel(n_jobs=min(config['computation']['n_jobs'], config['computation']['trials']), verbose=3, backend='loky') #loky #sequential multiprocessing\n",
    "evaluation_results_real_world_classification_multi = parallel_eval_real_world(delayed(evaluate_real_world_parallel_nested)(identifier_list=identifier_list_classification_multi[::-1], \n",
    "                                                                                                       random_seed_data=config['computation']['random_seed']+i,\n",
    "                                                                                                       random_seed_model=config['computation']['random_seed'],\n",
    "                                                                                                       config = config,\n",
    "                                                                                                       benchmark_dict = benchmark_dict,\n",
    "                                                                                                       metrics = config['computation']['metrics_class'],\n",
    "                                                                                                       verbosity = -1) for i in range(config['computation']['trials']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14abdf02-c317-4113-b1c9-f3a30afc0752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_table_save_results(benchmark_dict=benchmark_dict,\n",
    "                        evaluation_results_real_world=evaluation_results_real_world_classification_multi,\n",
    "                        identifier_list=identifier_list_classification_multi,                            \n",
    "                        identifier_string='multi_test',\n",
    "                        filepath=filepath,\n",
    "                        config=config)      \n",
    "\n",
    "plot_table_save_results(benchmark_dict=benchmark_dict,\n",
    "                        evaluation_results_real_world=evaluation_results_real_world_classification_multi,\n",
    "                        identifier_list=identifier_list_classification_multi,                            \n",
    "                        identifier_string='multi_valid',\n",
    "                        filepath=filepath,\n",
    "                        config=config)  \n",
    "\n",
    "plot_table_save_results(benchmark_dict=benchmark_dict,\n",
    "                        evaluation_results_real_world=evaluation_results_real_world_classification_multi,\n",
    "                        identifier_list=identifier_list_classification_multi,                            \n",
    "                        identifier_string='multi_train',\n",
    "                        filepath=filepath,\n",
    "                        config=config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea38cb0-9c56-4b2f-abff-4f8b709a9909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:#if False and config['gdt']['objective'] == 'classification':\n",
    "    plot_dt_comparison(evaluation_results_real_world=evaluation_results_real_world_classification_multi,\n",
    "                      identifier_list=identifier_list_classification_multi,\n",
    "                      identifier_string='multi_test',\n",
    "                      timestr=timestr,\n",
    "                      config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c2e34-b71b-4821-bc1e-79a8a3a707fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "if config['computation']['use_gpu']:\n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
