{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2de044-863d-4243-b187-4979ad5f316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'gdt': {\n",
    "        'depth': 11,\n",
    "                \n",
    "        'learning_rate_index': 0.05,\n",
    "        'learning_rate_values': 0.01,\n",
    "        'learning_rate_leaf': 0.005,\n",
    "        \n",
    "        'dropout': 0.2, #0.2 oder 0.5\n",
    "        \n",
    "        \n",
    "        'initializer_values': 'GlorotUniform', \n",
    "        'initializer_index': 'GlorotUniform', \n",
    "        'initializer_leaf': 'GlorotUniform', \n",
    "        \n",
    "        'optimizer': 'adam', \n",
    "        \n",
    "        'batch_size': 256,#120\n",
    "        'epochs': 1,\n",
    "        \n",
    "        'restarts': 0,#\n",
    "        'restart_type': 'loss', #'loss', 'metric'\n",
    "        \n",
    "        'early_stopping_epochs': 600,\n",
    "        'early_stopping_type': 'loss', #'loss', 'metric'\n",
    "        'early_stopping_epsilon': 0.0,\n",
    "        \n",
    "        'pretrain_epochs': 30,\n",
    "    },\n",
    "    \n",
    "    'preprocessing': {\n",
    "        'balance_threshold': 0.5,#.25, #if minclass fraction less than threshold/num_classes | #0=no rebalance, 1=rebalance all\n",
    "        'normalization_technique': 'mean', #'min-max'\n",
    "    },\n",
    "\n",
    "    'computation': {\n",
    "        'random_seed': 42,\n",
    "        'trials': 11, # fixed to 1 for HPO\n",
    "        \n",
    "        'use_best_hpo_result': True,\n",
    "        'force_depth': False,\n",
    "        \n",
    "        'use_gpu': True,\n",
    "        'gpu_numbers': '3',#'1',\n",
    "        'n_jobs': 20, #vorher 20\n",
    "        'verbosity': 0,\n",
    "        \n",
    "        \n",
    "        'hpo': None,#'binary', #'binary', 'multi', 'regression'\n",
    "        'search_iterations': 300,\n",
    "        'cv_num': 3,     \n",
    "        \n",
    "        'metrics_class': ['f1', 'roc_auc', 'accuracy'],\n",
    "        \n",
    "        'metrics_reg': ['r2', 'neg_mean_absolute_percentage_error', 'neg_mean_absolute_error', 'neg_mean_squared_error'],\n",
    "        \n",
    "        'eval_metric_class': ['f1', 'roc_auc'], #f1 accuracy\n",
    "        'eval_metric_reg': 'r2', #r2 mae        \n",
    "        \n",
    "        'max_total_samples': 1000000,\n",
    "        'chunk_size': 1000,#default 200\n",
    "        'pretrain_size': 10000,\n",
    "    },\n",
    "    \n",
    "    'benchmarks': {       \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b0faf3-ffd3-46c6-bcfb-ddb3db3e30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict, config_training, metrics = prepare_training(identifier = 'BIN:agr_a', config = config)\n",
    "\n",
    "model_dict = {}\n",
    "\n",
    "verbosity = 1\n",
    "\n",
    "model_dict['GDT'] = GDT(number_of_variables = dataset_dict['number_of_variables'],\n",
    "            number_of_classes = dataset_dict['number_of_classes'],\n",
    "\n",
    "            objective = config_training['gdt']['objective'],\n",
    "\n",
    "            depth = config_training['gdt']['depth'],\n",
    "\n",
    "            learning_rate_index = config_training['gdt']['learning_rate_index'],\n",
    "            learning_rate_values = config_training['gdt']['learning_rate_values'],\n",
    "            learning_rate_leaf = config_training['gdt']['learning_rate_leaf'],\n",
    "\n",
    "            optimizer = config_training['gdt']['optimizer'],\n",
    "\n",
    "            loss = 'crossentropy',\n",
    "\n",
    "            initializer_values = config_training['gdt']['initializer_values'],\n",
    "            initializer_index = config_training['gdt']['initializer_index'],\n",
    "            initializer_leaf = config_training['gdt']['initializer_leaf'],        \n",
    "\n",
    "            random_seed = config_training['computation']['random_seed'],\n",
    "            verbosity = verbosity)#5      \n",
    "\n",
    "\n",
    "history = model_dict['GDT'].partial_fit(dataset_dict['X_train'],\n",
    "          dataset_dict['y_train'],\n",
    "\n",
    "          batch_size=config_training['gdt']['batch_size'], \n",
    "          epochs=config_training['gdt']['epochs'], \n",
    "\n",
    "          restarts = 0,#config_test['gdt']['restarts'], \n",
    "          #restart_type=config_test['gdt']['restart_type'], \n",
    "\n",
    "          #early_stopping_epochs=config_training['gdt']['early_stopping_epochs'], \n",
    "          #early_stopping_type=config_test['gdt']['early_stopping_type'],\n",
    "\n",
    "          valid_data=(dataset_dict['X_valid'], dataset_dict['y_valid']))\n",
    "\n",
    "\n",
    "model_dict['sklearn'] = DecisionTreeClassifier(max_depth=config_training['gdt']['depth'], \n",
    "                                      random_state=config_training['computation']['random_seed'])\n",
    "\n",
    "model_dict['sklearn'].fit(dataset_dict['X_train'], \n",
    "                          dataset_dict['y_train'])\n",
    "\n",
    "\n",
    "# model_dict['GeneticTree'] = GeneticTree()\n",
    "# model_dict['GeneticTree'] = model_dict['GeneticTree'].fit(dataset_dict['X_train'].values, \n",
    "#                                                           dataset_dict['y_train'].values)        \n",
    "\n",
    "\n",
    "scores_dict = calculate_scores(model_dict = model_dict, \n",
    "                               dataset_dict = dataset_dict, \n",
    "                               scores_dict = prepare_score_dict(config=config_training), \n",
    "                               metrics = metrics)           \n",
    "\n",
    "#model.set_params(**config_training['gdt'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e84bd-c1ac-4535-9e03-867a6df77c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
